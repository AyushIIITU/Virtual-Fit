{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c23d2a-ded6-4b17-920e-0eac4fb325a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from services.load_food_embedding import df_recipes, food_embeddings, food_names, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a7c627-132b-4daf-b619-6c7b5fa58cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cce02659-825d-43c0-86fe-93f4e09e8407",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def find_best_match(query:str)->str:\n",
    "    \"\"\"Find the best match for a given query in the food names.\n",
    "    Args:\n",
    "        query (str): The input query to find the best match for.\n",
    "    Returns:\n",
    "        str: The food name that best matches the query.\n",
    "    \"\"\"\n",
    "    # Ensure the query is a string\n",
    "    if not isinstance(query, str):\n",
    "        raise ValueError(\"Query must be a string\")\n",
    "    query_embedding = model.encode([query])\n",
    "    similarities = cosine_similarity(query_embedding, food_embeddings)\n",
    "    best_idx = np.argmax(similarities)\n",
    "    return food_names[best_idx]\n",
    "@tool\n",
    "def get_food_details(food_name:str)->dict:\n",
    "    \"\"\"Get food details from the DataFrame.\n",
    "    Args:\n",
    "        food_name (str): The name of the food to retrieve details for.\n",
    "    Returns:\n",
    "        dict: A dictionary containing the food details, or None if not found.\n",
    "    \"\"\"\n",
    "    food_details = df_recipes[df_recipes[\"name\"] == food_name]\n",
    "    if not food_details.empty:\n",
    "        return food_details.to_dict(orient=\"records\")[0]\n",
    "    else:\n",
    "        return None\n",
    "@tool\n",
    "def find_best_food_match(text_array:list[str])->str:\n",
    "    \"\"\"Extract the most relevant food name by finding the closest match in recipe embeddings.\n",
    "    Args:\n",
    "        text_array (list[str]): A list of strings to find the best food match for.\n",
    "    Returns:\n",
    "        str: The food name that best matches the input text array.\n",
    "    Raises:\n",
    "        ValueError: If the input is not a list of strings.\n",
    "    \"\"\"\n",
    "    # Convert input list into a single meaningful string\n",
    "    combined_text = \" \".join(text_array)\n",
    "    \n",
    "    # Generate embedding for input text\n",
    "    input_embedding = model.encode([combined_text], convert_to_numpy=True)\n",
    "\n",
    "    # Compute cosine similarity with all recipes\n",
    "    similarities = cosine_similarity(input_embedding, food_embeddings)[0]\n",
    "\n",
    "    # Get the closest match index\n",
    "    best_match_idx = np.argmax(similarities)\n",
    "    \n",
    "    # Access food name directly if food_names is a list\n",
    "    return food_names[best_match_idx]  # Replace .iloc with direct indexing for lists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6a17b92-d4a8-4b79-bc66-80c4ca026c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "local_llm2 = \"llama3.1:8b\"\n",
    "llm2 = ChatOllama(model=local_llm2, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a18a758-45b8-4980-a38c-bd17cd5f7a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [find_best_match, get_food_details, find_best_food_match]\n",
    "llm_with_tools = llm2.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b571370b-d62f-43f5-bd9d-3ed1c525776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "local_llm = \"granite3.2-vision:2b\"\n",
    "llm = ChatOllama(model=local_llm, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23c0dade-6d6d-4cc0-b3f8-57cb2bd2df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [find_best_match, get_food_details, find_best_food_match]\n",
    "llm_with_tools2 = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c623bf86-d2fd-4b9d-a96f-7e746ddff018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_food_details',\n",
       "  'args': {'food_name': 'samosa'},\n",
       "  'id': 'a59af5b9-1697-4897-be34-59cb09aac5a9',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"what is the food details of samosa\"\n",
    "llm_with_tools.invoke(query).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcbb612b-88d9-4e4e-890e-747c4a1cd1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'get_food_details', 'args': '{\"food_name\": \"samosa\"}', 'id': '1c8c0065-85c6-48d9-891a-5f2fbc08a0bb', 'index': None, 'type': 'tool_call_chunk'}]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "async for chunk in llm_with_tools.astream(query):\n",
    "    print(chunk.tool_call_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ee5a82-79f6-4a1b-af61-cc499c5c4452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
