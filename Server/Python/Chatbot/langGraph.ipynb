{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LLM\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "local_llm = \"llama3:latest\"\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "llm_json_mode = ChatOllama(model=local_llm, temperature=0, format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Load multiple URLs to have more documents\n",
    "urls = [\n",
    "    \"https://iiitu.ac.in\",\n",
    "    \"https://iiitu.ac.in/about\",  # Add more URLs from the same site\n",
    "    \"https://iiitu.ac.in/academics\" ,\n",
    "    \"https://iiitu.ac.in/campuslife\",# Add more URLs from the same site\n",
    "    \"https://iiitu.ac.in/placements\" ,\n",
    "    \"https://iiitu.ac.in/news\" ,\n",
    "]\n",
    "\n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ")\n",
    "\n",
    "all_chunks = []\n",
    "for url in urls:\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "    all_chunks.extend(chunks)\n",
    "\n",
    "# Switch to HuggingFaceEmbeddings which works locally\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\"  # This is a small, efficient embedding model\n",
    ")\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    documents=all_chunks,\n",
    "    embedding=embedding,\n",
    ")\n",
    "\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"I'd be happy to help!\\n\\nAccording to various sources, including the official website of Indian Institute of Information Technology Una (IIIT Una) and other educational portals, here are some placement statistics:\\n\\n* Average package: ₹8-12 lakhs per annum\\n* Highest package: ₹15-20 lakhs per annum\\n* Placement rate: around 80-90%\\n* Top recruiters: companies like Google, Microsoft, Amazon, IBM, Accenture, etc.\\n\\nPlease note that these figures are subject to change and might not be up-to-date. I would recommend checking the official website of IIIT Una or contacting their placement cell for more accurate and current information.\\n\\nWould you like me to provide more details on this topic or explore other related aspects?\" response_metadata={'model': 'llama3:latest', 'created_at': '2025-03-15T19:38:27.8915234Z', 'done': True, 'done_reason': 'stop', 'total_duration': 31540568600, 'load_duration': 57316100, 'prompt_eval_count': 92, 'prompt_eval_duration': 655000000, 'eval_count': 152, 'eval_duration': 30827000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-154bbeea-9275-4836-be81-7ecb18411e2b-0' usage_metadata={'input_tokens': 92, 'output_tokens': 152, 'total_tokens': 244}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a chatbot that helps users find relevant information. \\n\n",
    "    \n",
    "    \n",
    "    Question: {question} \\n\n",
    "    Context: \\n\\n {documents} \\n\\n\n",
    "    \n",
    "    Give a relevant answer to the question. \\n\n",
    "    If you do not have enough information, you can ask for more information. \\n\n",
    "    Otherwise, you can say that you do not have enough information. \\n\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")\n",
    "basicChain=prompt | llm\n",
    "question = \"what is placement statistics of IIIT Una?\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "response=basicChain.invoke({\"question\": question, \"documents\": doc_txt})\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fitenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
